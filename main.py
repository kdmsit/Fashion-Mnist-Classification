# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VBj6NeQiR8xrHtDm_XgkpAh6bnoqrjCK
"""

import torch
import datetime
import torchvision
import numpy as np
from torch import nn
from tqdm import tqdm
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms
from torch.autograd import Variable
from sklearn.metrics import confusion_matrix
from matplotlib import pyplot as plt

# from google.colab import drive
# drive.mount('/content/gdrive')

trans_img = transforms.Compose([transforms.ToTensor()])
test_dataset = torchvision.datasets.FashionMNIST("./data/", train=False, transform=trans_img, download=True)
testloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle = True)

# nnpath = F"/content/gdrive/My Drive/model/nn.pkl"
# cnnpath = F"/content/gdrive/My Drive/model/cnn.pkl"
from sklearn.metrics import confusion_matrix
nnpath = "models/nn.pkl"
cnnpath = "models/cnn.pkl"

class MLP(nn.Module):
  def __init__(self, n_classes=10):
    super(MLP, self).__init__()
    self.n_class=n_classes
    self.fc1 = nn.Linear(784, 64)
    self.fc2 = nn.Linear(64, 32)
    self.fc3 = nn.Linear(32, 16)
    self.clf = nn.Linear(16, n_classes)
  def forward(self, x):
    x = x.view(-1, 784)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = F.relu(self.fc3(x))
    out = self.clf(x)
    return out

class CNN(nn.Module):
  def __init__(self, n_classes=10):
        emb_dim = 512
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)
        self.bn2=nn.BatchNorm2d(64)
        self.fc1 = nn.Linear(64*7*7, emb_dim)
        self.fc2 = nn.Linear(emb_dim, 128)
        self.clf = nn.Linear(128, n_classes)
  def forward(self, x):
    
    x = F.max_pool2d(F.relu(self.bn1(self.conv1(x))), 2)
    x = F.max_pool2d(F.relu(self.bn2(self.conv2(x))), 2)
    x = x.view(-1,64*7*7)
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    out = self.clf(x)
    return out

"""CNN Test"""

device = torch.device("cpu")
cnn_model = CNN(10).to(device)
cnn_model.load_state_dict(torch.load(cnnpath,map_location=torch.device('cpu')))
test_total=0
count=0
test_correct=0
avg_loss=0
y_gt = []
y_pred_label = []
for batch_idx, (img, target) in enumerate(testloader):
  img = Variable(img).to(device)
  target = Variable(target).to(device)
  out = cnn_model(img)
  y_pred = F.softmax(out, dim=1)
  y_pred_label_tmp = torch.argmax(y_pred, dim=1)
  loss = F.cross_entropy(out, target)
  avg_loss=avg_loss+loss
  # Add the labels
  y_gt += list(target.numpy())
  y_pred_label += list(y_pred_label_tmp.numpy())
  count=count+1

print("Confusion Matrix For CNN")
confusion_matrix_cnn=confusion_matrix(y_gt,y_pred_label)
print(confusion_matrix_cnn)
print("\n")
print("\n")
# fig = plt.figure()
# plt.matshow(confusion_matrix_cnn)
# plt.title('Confusion Matrix For CNN')
# plt.colorbar()
# plt.ylabel('True Label')
# plt.xlabel('Predicated Label')
# plt.savefig('confusion_matrix_cnn.jpg')

with open("convolution-neural-net.txt", 'w') as f:
  f.write("Loss on Test Data : {}\n".format(avg_loss/count))
  f.write("Accuracy on Test Data : {}\n".format(np.mean(np.array(y_gt) == np.array(y_pred_label))))
  f.write("gt_label,pred_label \n")
  for idx in range(len(y_gt)):
      f.write("{},{}\n".format(y_gt[idx], y_pred_label[idx]))
# print("Test Accuracy:"+str(test_acc))

"""MLP Test"""

device = torch.device("cpu")
nn_model = MLP(10).to(device)
nn_model.load_state_dict(torch.load(nnpath,map_location=torch.device('cpu')))
test_total=0
count=0
test_correct=0
avg_loss=0
y_gt = []
y_pred_label = []
for batch_idx, (img, target) in enumerate(testloader):
  img = Variable(img).to(device)
  target = Variable(target).to(device)
  out = nn_model(img)
  y_pred = F.softmax(out, dim=1)
  y_pred_label_tmp = torch.argmax(y_pred, dim=1)
  loss = F.cross_entropy(out, target)
  avg_loss=avg_loss+loss
  # Add the labels
  y_gt += list(target.numpy())
  y_pred_label += list(y_pred_label_tmp.numpy())
  count=count+1

print("Confusion Matrix For MLP")
confusion_matrix_mlp=confusion_matrix(y_gt,y_pred_label)
print(confusion_matrix_mlp)
print("\n")
print("\n")
# fig = plt.figure()
# plt.matshow(confusion_matrix_mlp)
# plt.title('Confusion Matrix For MLP')
# plt.colorbar()
# plt.ylabel('True Label')
# plt.xlabel('Predicated Label')
# plt.savefig('confusion_matrix_mlp.jpg')

with open("multi-layer-net.txt", 'w') as f:
  f.write("Loss on Test Data : {}\n".format(avg_loss/count))
  f.write("Accuracy on Test Data : {}\n".format(np.mean(np.array(y_gt) == np.array(y_pred_label))))
  f.write("gt_label,pred_label \n")
  for idx in range(len(y_gt)):
      f.write("{},{}\n".format(y_gt[idx], y_pred_label[idx]))
# print("Test Accuracy:"+str(test_acc))